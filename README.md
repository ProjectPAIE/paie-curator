# PAIE Curator

**A Local LLM Listener That Learns With You**

---

## ðŸš€ What This Is

This is the first operational node in a Mesh.  
A listener. A watcher. A curator of intelligence.

It connects to a Redis queue and listens for escalated LLM failures â€” things your models *couldnâ€™t classify*, or *got wrong*, or *needed help thinking about again*. Itâ€™s schema-aware. Human-aligned. And model-agnostic.

You donâ€™t need our front-end. You donâ€™t need a massive model.  
All you need is **a model that knows when itâ€™s unsure**, and this listener will do the rest.

---

## ðŸ§  Why We Built This

Most current "MCP" systems focus on RAG, vector search, or agent orchestration.  
We chose something simpler. **Structured escalation** â€” one of the most overlooked tools in LLM engineering.

If you want smarter models, you donâ€™t need bigger ones.  
You need better memory.  
You need **a place for the misses to go**.  
Thatâ€™s what this is.

We built it because we were tired of everyone skipping the hard part: _structured thought_.

---

## ðŸ“¦ Whatâ€™s Inside

- `core/`: Schema router, fallback handler, structured ingest logic
- `mcp/`: Real-time Redis listener (`mcp_listener.py`)
- `main.py`: Entry point if you want CLI testing
- `check_escalations.py`: View what your models escalated
- `fail_log.jsonl`: Output of escalated records

---

## ðŸ›  How to Use

1. Start a Redis server locally (default: `localhost:6379`)
2. Run the listener:

   ```bash
   ./start_listener.sh
